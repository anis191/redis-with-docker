# ğŸ“” Redis Streams

Redis **Streams** à¦¹à¦²à§‹ **append-only log / event stream data structure**à¥¤
à¦à¦Ÿà¦¿ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à¦¾ à¦¹à§Ÿ à¦¯à¦–à¦¨ **events, messages, logs, real-time data flow** handle à¦•à¦°à¦¤à§‡ à¦¹à§Ÿà¥¤

ğŸ‘‰ à¦¸à¦¹à¦œà¦­à¦¾à¦¬à§‡:

* Data à¦¶à§à¦§à§ **append** à¦¹à§Ÿ
* Order à¦¸à¦¬à¦¸à¦®à§Ÿ **maintained**
* Consumer group à¦¦à¦¿à§Ÿà§‡ multiple consumers handle à¦•à¦°à¦¾ à¦¯à¦¾à§Ÿ

---

## ğŸ”¹ Redis Stream à¦•à§€?

* Data type: **Stream**
* Structure:

```
stream_key â†’ [
  ID â†’ { field : value },
  ID â†’ { field : value },
  ...
]
```

Example:

```
orders â†’ [
  1700000000000-0 â†’ { user:1, item:"book" }
]
```

---

## 1ï¸âƒ£ Add data to Stream â€” `XADD`

### Example: Order events

```bash
XADD orders * user_id 1 product "book" price 350
```

ğŸ“Œ Output:

```
1700001234567-0
```

ğŸ” Explanation:

* `orders` â†’ stream key
* `*` â†’ auto-generated ID (timestamp-based)
* fieldâ€“value pairs â†’ event data

---

## 2ï¸âƒ£ Read stream entries â€” `XRANGE`

```bash
XRANGE orders - +
```

ğŸ“Œ Output (example):

```
1) 1700001234567-0
   1) "user_id" "1"
   2) "product" "book"
   3) "price" "350"
```

ğŸ‘‰ `- +` à¦®à¦¾à¦¨à§‡ â†’ from start to end

---

## 3ï¸âƒ£ Read last N messages

```bash
XREVRANGE orders + - COUNT 1
```

ğŸ‘‰ Latest event à¦¦à§‡à¦–à¦¤à§‡ à¦–à§à¦¬ useful

---

## 4ï¸âƒ£ Consumer Groups â€” Core Feature

Streams-à¦à¦° à¦¸à¦¬à¦šà§‡à§Ÿà§‡ powerful feature à¦¹à¦²à§‹ **Consumer Groups**à¥¤

### Create consumer group

```bash
XGROUP CREATE orders order_group $
```

ğŸ” `$` â†’ start from new messages only

---

## 5ï¸âƒ£ Read as consumer â€” `XREADGROUP`

```bash
XREADGROUP GROUP order_group consumer1 COUNT 1 BLOCK 0 STREAMS orders >
```

ğŸ” Explanation:

* `consumer1` â†’ consumer name
* `>` â†’ new messages only
* `BLOCK 0` â†’ wait forever

---

## 6ï¸âƒ£ Acknowledge message â€” `XACK`

```bash
XACK orders order_group 1700001234567-0
```

ğŸ‘‰ Message processed mark à¦•à¦°à¦¾ à¦¹à§Ÿ

---

## 7ï¸âƒ£ Pending messages â€” `XPENDING`

```bash
XPENDING orders order_group
```

ğŸ‘‰ Crash à¦¹à¦²à§‡ unprocessed messages à¦¦à§‡à¦–à¦¾ à¦¯à¦¾à§Ÿ

---

## 8ï¸âƒ£ Real-World Use Cases

### ğŸ”¹ Order Processing System

* Web app â†’ order event push
* Worker â†’ order process

---

### ğŸ”¹ Chat System

```bash
XADD chat:room1 * user "anisul" msg "Hello"
```

---

### ğŸ”¹ Logging System

```bash
XADD logs * level "error" msg "DB down"
```

---

### ğŸ”¹ IoT / Sensor Data

```bash
XADD sensor:temp * value 32.5
```

---

## 9ï¸âƒ£ Stream vs List vs Pub/Sub

| Feature         | Stream           | List  | Pub/Sub      |
| --------------- | ---------------- | ----- | ------------ |
| Persistence     | âœ…                | âœ…     | âŒ            |
| Consumer Groups | âœ…                | âŒ     | âŒ            |
| Replay          | âœ…                | âŒ     | âŒ            |
| Use case        | Event processing | Queue | Live message |

ğŸ‘‰ Reliable messaging â†’ **Streams**
ğŸ‘‰ Simple queue â†’ Lists
ğŸ‘‰ Live broadcast â†’ Pub/Sub

---

## ğŸ”Ÿ Important Commands Summary

| Command      | Purpose         |
| ------------ | --------------- |
| `XADD`       | Add event       |
| `XRANGE`     | Read stream     |
| `XREVRANGE`  | Reverse read    |
| `XGROUP`     | Create group    |
| `XREADGROUP` | Consume message |
| `XACK`       | Acknowledge     |
| `XPENDING`   | Pending list    |

---

## ğŸ§  Learning Tips

1. Think **event-driven**
2. Always acknowledge (`XACK`)
3. Use consumer groups for scalability
4. Streams = reliable message queue

---

## âœ… Key Takeaway

* Redis Streams = persistent event log
* Ordered & reliable
* Perfect for microservices & background workers
* More powerful than Lists & Pub/Sub

---